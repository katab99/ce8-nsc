{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Project - Mandelbrot set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "\n",
    "import time\n",
    "#%load_ext line_profiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Preps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_MIN = -2\n",
    "RE_MAX = 1\n",
    "IM_MIN = -1.5\n",
    "IM_MAX = 1.5\n",
    "\n",
    "RE_SCALE = 1000\n",
    "IM_SCALE = 1000\n",
    "\n",
    "T = 2 # threshold\n",
    "I = 100 # iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = np.linspace(RE_MIN, RE_MAX, RE_SCALE)\n",
    "im = np.linspace(IM_MIN, IM_MAX, IM_SCALE) *1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visulalizing the results of algorithms\n",
    "def plotting(res, title):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(title)\n",
    "    plt.imshow(res, cmap='inferno', extent=[RE_MIN, RE_MAX, IM_MIN, IM_MAX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print out execution time\n",
    "# func_name : type of algorithm\n",
    "# m : real axis scale\n",
    "# n : imaginary axis scale\n",
    "# dt : execution time\n",
    "\n",
    "def print_exectime(func_name, m, n, dt):\n",
    "    print(f\"\\\n",
    "    Type: {func_name}\\n\\\n",
    "    Axes scale:\\n\\\n",
    "        Re: {m}\\n\\\n",
    "        Im: {n}\\n\\\n",
    "    Execution time : {dt:.4f} [s]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Naive Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(re_val, im_val, iter, thresh):\n",
    "    M = np.zeros((re_val.size, im_val.size))\n",
    "    \n",
    "    for a in range(re_val.size): \n",
    "        for b in range(im_val.size):\n",
    "            z = 0 + 0j\n",
    "            c = re_val[a] + im_val[b]\n",
    "\n",
    "            for i in range(iter):\n",
    "                z = z**2 + c\n",
    "            \n",
    "                if abs(z) > thresh:\n",
    "                    M[b, a] = i\n",
    "                    break\n",
    "            else:\n",
    "                M[b, a] = iter\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "M_naive = naive(re, im, I, T)\n",
    "dt = time.time() - t0\n",
    "\n",
    "print_exectime(\"Naive\", RE_SCALE, IM_SCALE, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit naive(re, im, I, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the result of Naive algorithm\n",
    "plotting(M_naive, \"Naive\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Numpy Vectorized Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looping over every element, use Numpy vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized(re_val, im_val, iter, thresh):\n",
    "    M = np.zeros((re_val.size, im_val.size))\n",
    "    z = np.zeros((re_val.size, im_val.size), dtype=complex)\n",
    "    c = re_val + im_val[:, np.newaxis]\n",
    "\n",
    "    for i in range(iter):\n",
    "        z = z**2 + c\n",
    "        M[thresh <= abs(z)] = i\n",
    "\n",
    "    M[M == 0] = iter\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_vec = time.time()\n",
    "M_vec = vectorized(re, im, I, T)\n",
    "dt_vec = time.time() - t0_vec\n",
    "\n",
    "print_exectime(\"Vectorized\", RE_SCALE, IM_SCALE, dt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit vectorized(re, im, I, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(M_vec, \"Vectorized\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Numba Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def naive_numba(re_val, im_val, iter, thresh):\n",
    "    M = np.zeros((re_val.size, im_val.size))\n",
    "\n",
    "    for a in range(re_val.size): \n",
    "        for b in range(im_val.size):\n",
    "            z = 0 + 0j\n",
    "            c = re_val[a] + im_val[b]\n",
    "\n",
    "            for i in range(iter):\n",
    "                z = z**2 + c\n",
    "            \n",
    "                if abs(z) > thresh:\n",
    "                    M[b, a] = i\n",
    "                    break\n",
    "            else:\n",
    "                M[b, a] = iter\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_numba = time.time()\n",
    "M_numba = naive_numba(re, im, I, T)\n",
    "dt_numba = time.time() - t0_numba\n",
    "\n",
    "print_exectime(\"Numba\", RE_SCALE, IM_SCALE, dt_numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit naive_numba(re, im, I, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(M_numba, \"Numba\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Parallel Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import multiprocessing as mp\n",
    "import parallel_mandelbrot as pmb \n",
    "# to parallelize in Jupyter Notebook, the task function must be in an outside .py file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 100\n",
    "PROC_NUM  = [num for num in range(1, mp.cpu_count() + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['proc_num', 'chunks', 'time'])\n",
    "\n",
    "comp_matrix = re + im[:, np.newaxis]\n",
    "items = [(C, I, T) for C in comp_matrix]\n",
    "\n",
    "\n",
    "for proc_num in PROC_NUM: \n",
    "    for chunk in range(1, CHUNK_SIZE):\n",
    "        t0 = time.time()\n",
    "    \n",
    "        pool = mp.Pool(processes=proc_num)\n",
    "        res = [pool.starmap(pmb.parallel_mb, items, chunksize=chunk)]\n",
    "    \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        new_row = pd.Series({'proc_num' : proc_num, \\\n",
    "                            'chunks' : chunk, \\\n",
    "                            'time': time.time() - t0})\n",
    "        \n",
    "        df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "\n",
    "#end = [r.get() for r in res]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = 'output.csv'\n",
    "df = pd.read_csv(FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speedup(df, chunk_nums):\n",
    "    df_new = pd.DataFrame() # this will return \n",
    "\n",
    "    \n",
    "    # iterate through CHUNK_NUMS\n",
    "    for chunk in range(1, chunk_nums):\n",
    "        df_temp = df.copy() # for the different size of chunks\n",
    "        \n",
    "        # filtering the chunksize to get one [proc_num = 1] time value \n",
    "        df_temp = df_temp[df_temp['chunks'] == chunk]\n",
    "\n",
    "        proc1_time = []\n",
    "        # get the time for proc_num == 1, and create a list \n",
    "        for i in range(len(df_temp.index)):\n",
    "            proc1_time.append(df_temp[df_temp['proc_num'] == 1]['time'].item())\n",
    "\n",
    "        # add list as a new column ['proc1_time']\n",
    "        df_temp['proc1_time'] = proc1_time\n",
    "        df_new = pd.concat([df_new, df_temp], ignore_index=True) # append rows to the new dataframe\n",
    "    \n",
    "    # create speedup col -> divide proc1_time / time\n",
    "    df_new['speedup'] = df_new['proc1_time'] / df_new['time']\n",
    "    df_new = df_new.drop(columns='proc1_time')\n",
    "\n",
    "    # return dataframe with speedup column\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_speedup(df, CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['proc_num']\n",
    "y = df['chunks']\n",
    "z = df['time']\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(x, y, z, cmap='plasma')\n",
    "\n",
    "ax.set_xlabel('Number or Processors')\n",
    "ax.set_ylabel('Number of Chunks')\n",
    "ax.set_zlabel('Time [s]')\n",
    "ax.set_title('Performance of Parallelization [Execution Time]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['proc_num']\n",
    "y = df['chunks']\n",
    "z = df['speedup']\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(x, y, z, cmap='plasma')\n",
    "\n",
    "ax.set_xlabel('Number or Processors')\n",
    "ax.set_ylabel('Number of Chunks')\n",
    "ax.set_zlabel('Speedup')\n",
    "ax.set_title('Performance of Parallelization [Speedup]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data of shortest execution time\n",
    "df[df['time'] == min(df['time'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PROC_NUM = 5\n",
    "BEST_CHUNKS_NUM = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with biggest speedup\n",
    "df[df['speedup'] == max(df['speedup'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save data from iteration, not to iterate through again\n",
    "from pathlib import Path  \n",
    "\n",
    "filepath = Path('output.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True) \n",
    "df.to_csv(filepath, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize with Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize(func, proc_num, chunk_num, re_scale, im_scale, iter, thresh):\n",
    "    comp_matrix = re_scale + im_scale[:, np.newaxis]\n",
    "    items = [(C, iter, thresh) for C in comp_matrix]\n",
    "    pool = mp.Pool(processes=proc_num)\n",
    "    output = [pool.starmap(func, items, chunksize=chunk_num)]\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_parallel = time.time()\n",
    "M_parallel = parallelize(pmb.parallel_mb, BEST_PROC_NUM, BEST_CHUNKS_NUM, re, im, I, T)\n",
    "dt_parallel = time.time() - t0_parallel\n",
    "\n",
    "print_exectime(\"Parallelized\", RE_SCALE, IM_SCALE, dt_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit parallelize(pmb.parallel_mb, BEST_PROC_NUM, BEST_CHUNKS_NUM, re, im, I, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting(M_parallel[0], \"Parallelized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43776ef8a41ec75c20495dcfe4d6fc4bcf7634dda4e8caa69e1b16c605887698"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
